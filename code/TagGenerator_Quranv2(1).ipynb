{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwbLSd-MiExm",
        "outputId": "fe6ab1cd-7396-46e1-a79d-de817300c195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (0.28.0)\n",
            "Requirement already satisfied: python-dotenv in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (1.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from groq) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/nebulamind/miniconda3/envs/finetuning/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install groq python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItjMjgc4gjxd",
        "outputId": "5ca2a08a-0252-4cd7-dae2-43fed75ac9fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import List, Dict, Optional\n",
        "from groq import Groq\n",
        "from dataclasses import dataclass\n",
        "from dotenv import load_dotenv\n",
        "import tiktoken  # For token counting\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lk0_caTUgl01"
      },
      "outputs": [],
      "source": [
        "# Central configuration for file paths\n",
        "FILE_CONFIG = {\n",
        "    'input_csv': \"/media/nebulamind/AI Lab/AI Lab/AskDeen/dataset/quran_tags_final_with_translations_structured1.xlsx\",\n",
        "    'output_csv': '/home/nebulamind/Documents/AI Lab/AskDeen/outputs/complete_tags_with_scrapping.csv'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NBa9XKKBgnn5"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TagGenerationConfig:\n",
        "    \"\"\"Configuration for tag generation\"\"\"\n",
        "    api_key: str = os.getenv(\"GROQ_API_KEY\")\n",
        "    model_name: str = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
        "    context_window: int = 3  # 3 rows above and below\n",
        "    max_retries: int = 3\n",
        "    delay_between_calls: float = 0.5  # Groq is generally faster, can reduce delay\n",
        "    temperature: float = 0.2\n",
        "    max_tokens: int = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fPnSGGVGgssY"
      },
      "outputs": [],
      "source": [
        "def count_tokens(text: str, model: str = \"meta-llama/llama-4-maverick-17b-128e-instruct\") -> int:\n",
        "    \"\"\"Count the number of tokens in a text string\"\"\"\n",
        "    try:\n",
        "        # Use cl100k_base encoding which is used by GPT-4 and similar models\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "        return len(encoding.encode(text))\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not count tokens: {e}\")\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def create_optimized_prompt(context_data: dict) -> str:\n",
        "#     \"\"\"Create a balanced prompt for Quranic verse tag generation (1000-1100 words)\"\"\"\n",
        "\n",
        "#     prompt = \"\"\"Generate 2 conceptual tags that capture the core semantic themes of the given Quranic verse.\n",
        "#     Tags must be semantically rich, contextually accurate, and user-focused.\n",
        "\n",
        "# CONTEXT VERSES:\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "#     # Add context verses\n",
        "#     # for row in context_data[\"context_rows\"]:\n",
        "#     #     marker = \">>> TARGET VERSE (Generate tags for this) <<<\" if row[\"is_target\"] else \"\"\n",
        "#     #     prompt += f\"Verse ID: {row['id']} {marker}\\n\"\n",
        "#     #     prompt += f\"Translation: {row['translation']}\\n\\n\"\n",
        "#     target_index = None\n",
        "#     for i, row in enumerate(context_data[\"context_rows\"]):\n",
        "#       if row[\"is_target\"]:\n",
        "#           target_index = i\n",
        "#           break\n",
        "\n",
        "#     if target_index is not None:\n",
        "#       # Get previous, target, and next verses\n",
        "#       previous_verse2 = context_data[\"context_rows\"][target_index - 2] if target_index-1 > 0 else None\n",
        "#       previous_verse1 = context_data[\"context_rows\"][target_index - 1] if target_index > 0 else None\n",
        "\n",
        "#       target_verse = context_data[\"context_rows\"][target_index]\n",
        "#       next_verse1 = context_data[\"context_rows\"][target_index + 1] if target_index < len(context_data[\"context_rows\"])-1 else None\n",
        "#       next_verse2 = context_data[\"context_rows\"][target_index + 2] if target_index < len(context_data[\"context_rows\"])-2 else None\n",
        "\n",
        "#     # Build the new prompt format\n",
        "#       if previous_verse1:\n",
        "#           print(\"P1 done\")\n",
        "#           prompt += f\"*Previous1:* {previous_verse1['translation']}\\n\"\n",
        "#       if previous_verse2:\n",
        "#           prompt += f\"*Previous2:* {previous_verse2['translation']}\\n\"\n",
        "\n",
        "#       prompt += f\"*TARGET:* {target_verse['translation']}\\n\"\n",
        "#       if next_verse1:\n",
        "#           prompt += f\"*Next1:* {next_verse1['translation']}\\n\"\n",
        "#       if next_verse2:\n",
        "#           prompt += f\"*Next2:* {next_verse2['translation']}\\n\"\n",
        "\n",
        "#     prompt += \"\"\" ## Focus\n",
        "# - What is this verse fundamentally about?\n",
        "# - What are the main concepts and themes present?\n",
        "# - What theological/spiritual/moral domains does it address?\n",
        "\n",
        "# ## Conceptual Tag Categories\n",
        "# 1. **About Allah**: allah-names, allah-mercy, allah-power, divine-love, allah-forgiveness\n",
        "# 2. **About Prophets**: prophet-stories, prophet-teachings, messenger-guidance, prophetic-examples\n",
        "# 3. **Prayer & Worship**: salah-guidance, dua-supplications, dhikr-remembrance, worship-methods, spiritual-connection\n",
        "# 4. **Good Character**: honesty-truth, kindness-compassion, patience-perseverance, humility-modesty, gratitude-thankfulness\n",
        "# 5. **Family & Relationships**: parent-respect, marriage-love, children-upbringing, family-harmony, social-bonds\n",
        "# 6. **Daily Life Guidance**: halal-haram, life-decisions, problem-solving, personal-growth, righteous-living\n",
        "# 7. **Charity & Helping**: zakat-sadaqah, helping-needy, community-care, generosity-giving, social-responsibility\n",
        "# 8. **Afterlife & Judgment**: paradise-heaven, hell-warning, day-judgment, life-after-death, divine-justice\n",
        "\n",
        "# ## Guidelines\n",
        "# - Use 2-3 words maximum per tag\n",
        "# - Focus on abstract concepts rather than specific practices\n",
        "# - Think semantically, not functionally\n",
        "# - Avoid overlapping with practical applications\n",
        "\n",
        "# ## Output Format:\n",
        "# {\n",
        "#     \"verse\": \"verse text\",\n",
        "#     \"conceptual_tags\": [\"concept-1\", \"concept-1\"]\n",
        "# }\n",
        "# \"\"\"\n",
        "\n",
        "#     return prompt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_optimized_prompt(context_data: dict) -> str:\n",
        "    \"\"\"Create a balanced prompt for Quranic verse tag generation (1000-1100 words)\"\"\"\n",
        "\n",
        "    prompt = \"\"\"# Semantic Tag Generation for Quranic Verses - Vector Search Optimization\n",
        "\n",
        "## Task\n",
        "Generate semantic tags for the Target Verse that maximize discoverability in vector search systems. Tags should bridge user queries with verse content, enabling accurate retrieval across diverse Islamic learning and guidance scenarios.\n",
        "\n",
        "## Tag Philosophy\n",
        "- **Search-First**: Optimize for how users naturally search for Islamic guidance\n",
        "- **User-Centric**: Reflect authentic ways people express spiritual needs and questions\n",
        "- **Semantic Bridging**: Connect abstract spiritual concepts to concrete verse content\n",
        "- **Query Expansion**: Support both specific and exploratory search patterns\n",
        "- **RAG-Optimized**: Enhance retrieval accuracy in AI-powered Islamic guidance systems\n",
        "\n",
        "## Tag Generation Framework\n",
        "\n",
        "### Comprehensive Analysis Questions\n",
        "1. **Daily Practice**: Does this verse mention or relate to prayer, zakat, hajj, fasting, or other daily Islamic practices?\n",
        "2. **Legal Guidance**: Are there fiqh rulings, halal/haram distinctions, or jurisprudential principles?\n",
        "3. **Financial Matters**: Does it address business, interest, inheritance, wealth, or economic ethics?\n",
        "4. **Family/Social**: Are there guidance on marriage, parenting, family relations, or social interactions?\n",
        "5. **Moral Character**: What character traits, virtues, or behavioral guidance is mentioned?\n",
        "6. **Spiritual Development**: Are there elements of taqwa, tawakkul, spiritual purification, or inner growth?\n",
        "7. **Prophetic Stories**: Are there historical narratives or lessons from prophets?\n",
        "8. **Theological Concepts**: What divine attributes, Islamic beliefs, or theological principles are present?\n",
        "9. **Practical Problems**: Does it address real-life challenges people face (anxiety, illness, conflict, etc.)?\n",
        "10. **Worship Elements**: Are there specific ritual practices, prayer guidance, or worship instructions?\n",
        "\n",
        "### Tag Extraction Process\n",
        "1. **Read the verse carefully** - Identify all themes, not just the dominant one\n",
        "2. **Check surrounding context** - Look for additional applicable concepts\n",
        "3. **Consider user scenarios** - Think about ALL the ways people might search for this verse\n",
        "4. **Extract practical guidance** - Don't miss daily-life applications\n",
        "5. **Include historical elements** - Prophetic stories and historical lessons\n",
        "6. **Capture legal/fiqh aspects** - Any jurisprudential implications\n",
        "7. **Identify spiritual dimensions** - Growth, purification, divine connection aspects\n",
        "\n",
        "### Tag Categories (Extract ALL applicable concepts from verse)\n",
        "\n",
        "**Daily Islamic Practices**\n",
        "- `salah-prayer`, `wudu-ablution`, `zakat-charity`, `hajj-pilgrimage`, `fasting-ramadan`, `dua-supplication`, `dhikr-remembrance`\n",
        "\n",
        "**Islamic Law & Jurisprudence (Fiqh)**\n",
        "- `halal-permissible`, `haram-forbidden`, `inheritance-laws`, `business-transactions`, `marriage-nikah`, `divorce-talaq`, `witness-testimony`\n",
        "\n",
        "**Financial & Economic Guidance**\n",
        "- `riba-interest`, `trading-business`, `debt-loans`, `wealth-distribution`, `charity-sadaqah`, `financial-justice`, `economic-ethics`\n",
        "\n",
        "**Family & Social Relations**\n",
        "- `parent-obedience`, `marriage-guidance`, `child-upbringing`, `family-rights`, `neighbor-relations`, `community-bonds`, `social-justice`\n",
        "\n",
        "**Moral & Behavioral Guidance**\n",
        "- `honesty-truthfulness`, `patience-sabr`, `forgiveness-maghfira`, `humility-tawadu`, `justice-adl`, `kindness-ihsan`, `anger-management`\n",
        "\n",
        "**Spiritual Development**\n",
        "- `taqwa-consciousness`, `tawakkul-trust`, `repentance-tawba`, `gratitude-shukr`, `purification-tazkiya`, `spiritual-growth`, `inner-peace`\n",
        "\n",
        "**Divine Attributes & Names**\n",
        "- `allah-rahman`, `allah-rahim`, `divine-mercy`, `allah-knowledge`, `divine-wisdom`, `allah-justice`, `divine-forgiveness`\n",
        "\n",
        "**Prophetic Stories & Lessons**\n",
        "- `prophet-ibrahim`, `prophet-musa`, `prophet-isa`, `adam-creation`, `nuh-flood`, `historical-lessons`, `prophetic-guidance`\n",
        "\n",
        "**Eschatology & Afterlife**\n",
        "- `day-judgment`, `paradise-jannah`, `hell-jahannam`, `resurrection-qiyamah`, `accountability-hisab`, `afterlife-akhirah`\n",
        "\n",
        "**Worship & Rituals**\n",
        "- `prayer-times`, `qibla-direction`, `purification-tahara`, `friday-prayer`, `eid-celebration`, `pilgrimage-rites`, `funeral-janaza`\n",
        "\n",
        "**Personal Challenges & Solutions**\n",
        "- `anxiety-worry`, `illness-health`, `poverty-wealth`, `oppression-injustice`, `grief-loss`, `temptation-fitna`, `life-hardships`\n",
        "\n",
        "**Knowledge & Learning**\n",
        "- `seeking-knowledge`, `islamic-education`, `quran-recitation`, `hadith-study`, `religious-scholarship`, `wisdom-hikmah`\n",
        "\n",
        "**Community & Leadership**\n",
        "- `community-leadership`, `consultation-shura`, `collective-responsibility`, `social-reform`, `public-interest`, `governance-khilafah`\n",
        "\n",
        "## Guidelines\n",
        "\n",
        "### Tag Formatting\n",
        "- Use lowercase with hyphens: `divine-wisdom`\n",
        "- Maximum 3 words per tag (flexibility for semantic richness)\n",
        "- Combine Islamic terminology with accessible language\n",
        "- Ensure searchability across user backgrounds\n",
        "\n",
        "### Content Focus\n",
        "- **Extract ALL applicable concepts** - Don't limit to just the \"main\" theme\n",
        "- **Include practical applications** - Daily Islamic practices and guidance\n",
        "- **Capture legal/fiqh dimensions** - Jurisprudential implications and rulings\n",
        "- **Consider historical elements** - Prophetic stories and historical lessons  \n",
        "- **Address real-life problems** - Practical solutions for daily challenges\n",
        "- **Include spiritual aspects** - Growth, purification, and divine connection\n",
        "- **Cover worship practices** - Ritual guidance and religious obligations\n",
        "- **Identify moral teachings** - Character development and ethical behavior\n",
        "\n",
        "### User-Centric Approach\n",
        "- Think: \"What would someone type to find this verse?\"\n",
        "- Consider emotional and spiritual search contexts\n",
        "- Address both scholarly and personal guidance needs\n",
        "- Support diverse cultural expressions of Islamic concepts\n",
        "\n",
        "### Quality Criteria\n",
        "- **Semantic Accuracy**: Tags accurately represent verse meaning\n",
        "- **Search Relevance**: Tags match natural user query patterns  \n",
        "- **Islamic Authenticity**: Maintain theological accuracy\n",
        "- **Vector Optimization**: Enhance semantic similarity matching\n",
        "- **Contextual Appropriateness**: Fit within broader Quranic themes\n",
        "\n",
        "## Context Analysis Process\n",
        "\n",
        "1. **Read Target Verse**: Identify primary themes and concepts\n",
        "2. **Consider Context**: Analyze how previous/next verses inform meaning\n",
        "3. **Map User Needs**: Think about why someone would seek this guidance\n",
        "4. **Generate Tags**: Create tags that bridge content and user intent\n",
        "5. **Validate**: Ensure tags support diverse search scenarios\n",
        "\n",
        "---\n",
        "\n",
        "## Verse Context for Analysis\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    # Add context verses\n",
        "    # for row in context_data[\"context_rows\"]:\n",
        "    #     marker = \">>> TARGET VERSE (Generate tags for this) <<<\" if row[\"is_target\"] else \"\"\n",
        "    #     prompt += f\"Verse ID: {row['id']} {marker}\\n\"\n",
        "    #     prompt += f\"Translation: {row['translation']}\\n\\n\"\n",
        "    target_index = None\n",
        "    for i, row in enumerate(context_data[\"context_rows\"]):\n",
        "      if row[\"is_target\"]:\n",
        "          target_index = i\n",
        "          break\n",
        "\n",
        "    if target_index is not None:\n",
        "      # Get previous, target, and next verses\n",
        "      previous_verse2 = context_data[\"context_rows\"][target_index - 2] if target_index-1 > 0 else None\n",
        "      previous_verse1 = context_data[\"context_rows\"][target_index - 1] if target_index > 0 else None\n",
        "\n",
        "      target_verse = context_data[\"context_rows\"][target_index]\n",
        "      next_verse1 = context_data[\"context_rows\"][target_index + 1] if target_index < len(context_data[\"context_rows\"])-1 else None\n",
        "      next_verse2 = context_data[\"context_rows\"][target_index + 2] if target_index < len(context_data[\"context_rows\"])-2 else None\n",
        "\n",
        "    # Build the new prompt format\n",
        "      if previous_verse1 and previous_verse2:\n",
        "        #   print(\"P1 done\")\n",
        "          prompt += f\"*Previous Verse:* {previous_verse1['verse']}. \"\n",
        "          prompt += f\"{previous_verse2['verse']}.\\n \"\n",
        "          prompt += f\"*Previous Verse Translation:* {previous_verse1['translation']}. \"\n",
        "          prompt += f\"{previous_verse2['translation']}. \\n\\n\"\n",
        "\n",
        "      elif previous_verse1:\n",
        "          prompt += f\"*Previous Verse:* {previous_verse1['verse']}.\\n \"\n",
        "          prompt += f\"*Previous Verse Translation:* {previous_verse1['translation']}. \\n\\n\"\n",
        "\n",
        "      elif previous_verse2:\n",
        "            prompt += f\"*Previous Verse:* {previous_verse2['verse']}. \\n\"\n",
        "            prompt += f\"*Previous Verse Translation:* {previous_verse2['translation']}.\\n\\n\"\n",
        "\n",
        "      prompt += f\"*TARGET Verse:* {target_verse['verse']}\\n\"\n",
        "      prompt += f\"*TARGET Verse Translation:* {target_verse['translation']}\\n\\n\"\n",
        "      \n",
        "      \n",
        "      if next_verse1 and next_verse2:\n",
        "        #   print(\"P2 done\")\n",
        "          prompt += f\"*Next Verse:* {next_verse1['verse']}. \"\n",
        "          prompt += f\"{next_verse2['verse']}. \\n\"\n",
        "          prompt += f\"*Next Verse Translation:* {next_verse1['translation']}. \"\n",
        "          prompt += f\"{next_verse2['translation']}.\\n\\n \"\n",
        "\n",
        "      elif next_verse1:\n",
        "          prompt += f\"*Next Verse:* {next_verse1['verse']}. \\n\"\n",
        "          prompt += f\"*Next Verse Translation:* {next_verse1['translation']}. \\n\\n\"\n",
        "\n",
        "      elif next_verse2:\n",
        "            prompt += f\"*Next Verse:* {next_verse2['verse']}. \\n\"\n",
        "            prompt += f\"*Next Verse Translation:* {next_verse2['translation']}.\\n\\n\"\n",
        "\n",
        "    prompt += \"\"\"## Analysis Framework for This Verse\n",
        "\n",
        "### Semantic Content Analysis\n",
        "- Divine dialogue with angels about human creation\n",
        "- Angels questioning human potential for corruption\n",
        "- Allah's superior knowledge and divine wisdom\n",
        "- The establishment of humanity on earth\n",
        "\n",
        "### User Search Scenarios (Cover ALL these patterns)\n",
        "- **Daily Practice Queries**: \"verses about prayer times\", \"zakat calculation guidance\", \"hajj requirements\"\n",
        "- **Legal/Fiqh Questions**: \"inheritance laws in Islam\", \"what is halal/haram\", \"marriage rules\"\n",
        "- **Financial Guidance**: \"Islam and interest/riba\", \"business ethics\", \"debt in Islam\"\n",
        "- **Family Issues**: \"parent rights\", \"marriage problems\", \"child discipline\"\n",
        "- **Personal Challenges**: \"dealing with anxiety\", \"patience during hardship\", \"forgiveness\"\n",
        "- **Worship Questions**: \"how to pray\", \"ablution rules\", \"Friday prayer\"\n",
        "- **Moral Guidance**: \"honesty in business\", \"anger management\", \"being just\"\n",
        "- **Spiritual Growth**: \"getting closer to Allah\", \"repentance\", \"purifying heart\"\n",
        "- **Historical Learning**: \"story of Adam\", \"lessons from prophets\", \"historical events\"\n",
        "- **Theological Understanding**: \"Allah's attributes\", \"predestination\", \"divine wisdom\"\n",
        "\n",
        "## Real-World Examples\n",
        "\n",
        "**Example 1: Verse about Prayer**\n",
        "- Tags could include: `salah-prayer`, `prayer-times`, `spiritual-discipline`, `divine-connection`\n",
        "\n",
        "**Example 2: Verse about Business Ethics** \n",
        "- Tags could include: `business-transactions`, `honesty-truthfulness`, `halal-earning`, `economic-justice`\n",
        "\n",
        "**Example 3: Verse about Inheritance**\n",
        "- Tags could include: `inheritance-laws`, `family-rights`, `financial-distribution`, `justice-adl`\n",
        "\n",
        "**Example 4: Verse about Patience**\n",
        "- Tags could include: `patience-sabr`, `life-hardships`, `spiritual-growth`, `divine-testing`\n",
        "\n",
        "**Example 5: Verse about Prophet's Story**\n",
        "- Tags could include: `prophet-ibrahim`, `historical-lessons`, `faith-trials`, `divine-guidance`\n",
        "\n",
        "## Output Format:\n",
        "```json\n",
        "{\n",
        "    \"Topics\": [main topics],\n",
        "    \"Sub-Topics\": [sub-topics]   \n",
        "}\n",
        "```\n",
        "\n",
        "## Tag Validation Checklist\n",
        "- [ ] Tags accurately capture verse's core meaning\n",
        "- [ ] Tags support natural user search patterns\n",
        "- [ ] Tags maintain Islamic authenticity and accuracy\n",
        "- [ ] Tags enhance vector similarity matching\n",
        "- [ ] Tags are discoverable by diverse user backgrounds\n",
        "- [ ] Tags complement rather than duplicate each other\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NIDKqEsHg6VI"
      },
      "outputs": [],
      "source": [
        "class GroqQuranTagGenerator:\n",
        "    def __init__(self, config: TagGenerationConfig):\n",
        "        self.config = config\n",
        "        self.client = Groq(api_key=config.api_key)\n",
        "        self.total_input_tokens = 0\n",
        "        self.total_output_tokens = 0\n",
        "\n",
        "    \n",
        "    def get_contextual_rows(self, df: pd.DataFrame, current_index: int) -> Dict:\n",
        "        \"\"\"Get context rows (3 above and 3 below current row)\"\"\"\n",
        "        start_idx = max(0, current_index - 3)\n",
        "        end_idx = min(len(df), current_index + 3 + 1)\n",
        "\n",
        "        context_rows = []\n",
        "        target_row = None\n",
        "\n",
        "        for i in range(start_idx, end_idx):\n",
        "            # Assuming your CSV has columns 'ID' and 'Abdullah Yusuf Ali'\n",
        "            row_data = {\n",
        "                \"id\": str(df.iloc[i]['ID']),\n",
        "                \"verse\": str(df.iloc[i]['arabic']),\n",
        "                \"translation\": str(df.iloc[i]['translation']),\n",
        "                \"Topics\": str(df.iloc[i]['main_topic']),\n",
        "                \"Sub-Topics\": str(df.iloc[i]['subtopic'])\n",
        "            }\n",
        "\n",
        "            if i == current_index:\n",
        "                target_row = row_data\n",
        "                row_data[\"is_target\"] = True\n",
        "            else:\n",
        "                row_data[\"is_target\"] = False\n",
        "\n",
        "            context_rows.append(row_data)\n",
        "\n",
        "        return {\n",
        "            \"context_rows\": context_rows,\n",
        "            \"target_row\": target_row\n",
        "        }\n",
        "\n",
        "    def call_groq_api(self, prompt: str) -> Optional[Dict]:\n",
        "        \"\"\"Make API call to Groq with retry logic\"\"\"\n",
        "        # Count input tokens\n",
        "        input_tokens = count_tokens(prompt)\n",
        "        self.total_input_tokens += input_tokens\n",
        "\n",
        "        for attempt in range(self.config.max_retries):\n",
        "            try:\n",
        "                completion = self.client.chat.completions.create(\n",
        "                    model=self.config.model_name,\n",
        "                    messages=[\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"You are an expert Islamic scholar specializing in Quranic interpretation and semantic analysis. Always respond with valid JSON only.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": prompt\n",
        "                        }\n",
        "                    ],\n",
        "                    temperature=self.config.temperature,\n",
        "                    max_tokens=self.config.max_tokens,\n",
        "                    top_p=0.9,\n",
        "                    stream=False,  # Set to False for easier JSON parsing\n",
        "                    stop=None,\n",
        "                )\n",
        "\n",
        "                content = completion.choices[0].message.content.strip()\n",
        "\n",
        "                # Count output tokens\n",
        "                output_tokens = count_tokens(content)\n",
        "                self.total_output_tokens += output_tokens\n",
        "\n",
        "                # Parse JSON response\n",
        "                try:\n",
        "                    # Extract JSON from response if it contains extra text\n",
        "                    if '{' in content and '}' in content:\n",
        "                        json_start = content.find('{')\n",
        "                        json_end = content.rfind('}') + 1\n",
        "                        json_content = content[json_start:json_end]\n",
        "                        result = json.loads(json_content)\n",
        "\n",
        "                        # Validoutputsate required keys\n",
        "                        if all(key in result for key in ['Topics', 'Sub-Topics']):\n",
        "                            return result\n",
        "                        else:\n",
        "                            print(f\"Missing required keys in response: {result}\")\n",
        "                            return None\n",
        "\n",
        "                    else:\n",
        "                        print(f\"No JSON found in response: {content}\")\n",
        "                        return None\n",
        "\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"JSON parsing error: {e}\")\n",
        "                    print(f\"Raw Surah123response: {content}\")\n",
        "                    return None\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"API call attempt {attempt + 1} failed: {e}\")\n",
        "                if attempt < self.config.max_retries - 1:\n",
        "                    time.sleep(self.config.delay_between_calls * (attempt + 1))\n",
        "                else:\n",
        "                    return None\n",
        "\n",
        "        return None\n",
        "\n",
        "    def process_dataframe(self, df: pd.DataFrame, start_row: int = 0, end_row: Optional[int] = None) -> pd.DataFrame:\n",
        "        \"\"\"Process the entire dataframe to generate tags\"\"\"\n",
        "        if end_row is None:\n",
        "            end_row = len(df)\n",
        "\n",
        "        # Reset token counters\n",
        "        self.total_input_tokens = 0\n",
        "        self.total_output_tokens = 0\n",
        "\n",
        "        # Initialize new columns if they don't exist\n",
        "        for col in ['Verse', 'Topics', 'Sub-Topics']:\n",
        "            if col not in df.columns:\n",
        "                df[col] = None\n",
        "\n",
        "        processed_count = 0\n",
        "        failed_count = 0\n",
        "\n",
        "        print(f\"Starting tag generation for rows {start_row} to {end_row-1}\")\n",
        "        print(f\"Using model: {self.config.model_name}\")\n",
        "\n",
        "        for idx in range(start_row, min(end_row, len(df))):\n",
        "            print(f\"\\nProcessing row {idx + 1}/{len(df)} (ID: {df.iloc[idx]['ID']})\")\n",
        "\n",
        "            # Get contextual dataGROQ_API_KEY\n",
        "            context_data = self.get_contextual_rows(df, idx)\n",
        "\n",
        "            # Create prompt\n",
        "            prompt = create_optimized_prompt(context_data)\n",
        "\n",
        "            # Call Groq API\n",
        "            tags = self.call_groq_api(prompt)\n",
        "\n",
        "            if tags:\n",
        "                # Update dataframe with generated tags\n",
        "                # df.at[idx, 'Verse'] = df.iloc[i]['Abdullah Yusuf Ali']\n",
        "                print(idx)\n",
        "                df.at[idx, 'Topics'] = ', '.join(tags.get('Topics', []))\n",
        "                df.at[idx, 'Sub-Topics'] = ', '.join(tags.get('Sub-Topics', []))\n",
        "                # df.at[idx, 'reasoning'] = tags.get('reasoning', '').strip() \n",
        "                # df.at[idx, 'tag_3'] = tags.get('Secondary', '').strip()\n",
        "                processed_count += 1\n",
        "                print(f\"✓ Generated tags: {tags}\")\n",
        "            else:\n",
        "                failed_count += 1\n",
        "                print(f\"✗ Failed to generate tags for row {idx}\")\n",
        "\n",
        "            # Rate limiting\n",
        "            time.sleep(self.config.delay_between_calls)\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"PROCESSINGprevious_verse2 COMPLETE!\")\n",
        "        print(f\"Successfully processed: {processed_count} rows\")\n",
        "        print(f\"Failed: {failed_count} rows\")\n",
        "        print(f\"Success rate: {(processed_count/(processed_count+failed_count)*100):.1f}%\")\n",
        "        print(f\"Total input tokens: {self.total_input_tokens}\")\n",
        "        print(f\"Total output tokens: {self.total_output_tokens}\")\n",
        "        print(f\"Average tokens per verse: {self.total_input_tokens/processed_count:.1f} input, {self.total_output_tokens/processed_count:.1f} output\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def save_results(self, df: pd.DataFrame, output_path: str):\n",
        "        \"\"\"Save the results to a file\"\"\"\n",
        "        df.to_csv(output_path, index=False)\n",
        "        print(f\"Results saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "aNKp1H0Lg9-6"
      },
      "outputs": [],
      "source": [
        "def validate_tags(df: pd.DataFrame) -> Dict:\n",
        "    \"\"\"Validate generated tags and provide statistics\"\"\"\n",
        "    stats = {\n",
        "        'total_rows': len(df),\n",
        "        'rows_with_all_tags': 0,\n",
        "        'rows_with_missing_tags': 0,\n",
        "        'unique_tags': set(),\n",
        "        'tag_distribution': {}\n",
        "    }\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        tags = [row.get('tag_1'), row.get('tag_2')]\n",
        "        valid_tags = [tag for tag in tags if tag and str(tag).strip() and str(tag).strip() != 'nan']\n",
        "\n",
        "        if len(valid_tags) == 3:\n",
        "            stats['rows_with_all_tags'] += 1\n",
        "        else:\n",
        "            stats['rows_with_missing_tags'] += 1\n",
        "\n",
        "        # Add to unique tags and count frequency\n",
        "        for tag in valid_tags:\n",
        "            tag = str(tag).strip()\n",
        "            stats['unique_tags'].add(tag)\n",
        "            stats['tag_distribution'][tag] = stats['tag_distribution'].get(tag, 0) + 1\n",
        "\n",
        "    # Convert set to list for display\n",
        "    stats['unique_tags'] = list(stats['unique_tags'])\n",
        "    stats['total_unique_tags'] = len(stats['unique_tags'])\n",
        "\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "f1utgjfHhAY_"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the tag generation\"\"\"\n",
        "\n",
        "    # Configuration - Replace with your actual Groq API key\n",
        "    config = TagGenerationConfig(\n",
        "        api_key= os.getenv(\"GROQ_API_KEY\"),\n",
        "        model_name=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
        "        context_window=3,\n",
        "        max_retries=3,\n",
        "        delay_between_calls=0.5,\n",
        "        temperature=0.2,\n",
        "        max_tokens=256\n",
        "    )\n",
        "\n",
        "    # Load your data using the centralized file path\n",
        "    try:\n",
        "        df = pd.read_excel(FILE_CONFIG['input_csv'])\n",
        "        df = df[650:660] \n",
        "        print(f\"Loaded {len(df)} verses from CSV\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Please check the input file path in FILE_CONFIG: {FILE_CONFIG['input_csv']}\")\n",
        "        return\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = GroqQuranTagGenerator(config)\n",
        "\n",
        "    # Process the full dataset\n",
        "    print(\"Processing full dataset...\")\n",
        "    df_with_tags = generator.process_dataframe(df)  # No start_row or end_row specified means process all rows\n",
        "\n",
        "    # Save results using the centralized output path\n",
        "    output_file = FILE_CONFIG['output_csv']\n",
        "    generator.save_results(df_with_tags, output_file)\n",
        "\n",
        "    # Validate results\n",
        "    stats = validate_tags(df_with_tags)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"VALIDATION RESULTS:\")\n",
        "    print(f\"Total rows processed: {stats['total_rows']}\")\n",
        "    print(f\"Rows with all 3 tags: {stats['rows_with_all_tags']}\")\n",
        "    print(f\"Rows with missing tags: {stats['rows_with_missing_tags']}\")\n",
        "    print(f\"Unique tags generated: {stats['total_unique_tags']}\")\n",
        "    print(f\"Total tokens used: {generator.total_input_tokens + generator.total_output_tokens}\")\n",
        "    print(f\"Average tokens per verse: {generator.total_input_tokens/(stats['total_rows']+1):.1f} input, {generator.total_output_tokens/(stats['total_rows']+1):.1f} output\")\n",
        "\n",
        "    # Display sample results\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"SAMPLE RESULTS:\")\n",
        "    sample_cols = ['ID', 'Topic', 'Sub-Topic']\n",
        "    if all(col in df_with_tags.columns for col in sample_cols):\n",
        "        print(df_with_tags[sample_cols].head())\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"PROCESSING COMPLETE!\")\n",
        "    print(f\"Results saved to: {output_file}\")\n",
        "    print(\"Review the generated tags for quality and consistency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQLjiT2VhHOp",
        "outputId": "b4e2477a-e6ff-4303-da00-07f29aa870c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10 verses from CSV\n",
            "Columns: ['ID', 'translation', 'main_topic', 'subtopic', 'arabic']\n",
            "Processing full dataset...\n",
            "Starting tag generation for rows 0 to 9\n",
            "Using model: meta-llama/llama-4-maverick-17b-128e-instruct\n",
            "\n",
            "Processing row 1/10 (ID: 4|160)\n",
            "0\n",
            "✓ Generated tags: {'Topics': ['financial-guidance', 'islamic-law', 'jewish-practices', 'divine-punishment', 'economic-ethics'], 'Sub-Topics': ['riba-interest', 'halal-haram', 'food-laws', 'punishment-for-iniquity', 'hindering-others-from-allahs-way', 'wrongful-consumption-of-wealth', 'faith-rejection-punishment', 'believers-reward', 'prayer-maintenance', 'zakat-charity', 'faith-in-revelation']}\n",
            "\n",
            "Processing row 2/11 (ID: 4|161)\n",
            "1\n",
            "✓ Generated tags: {'Topics': ['financial-guidance', 'islamic-law', 'moral-behavior', 'divine-punishment', 'business-ethics'], 'Sub-Topics': ['riba-interest', 'unlawful-wealth', 'financial-injustice', 'punishment-for-disbelievers', 'business-transactions', 'halal-earning', 'economic-justice', 'moral-accountability']}\n",
            "\n",
            "Processing row 3/12 (ID: 4|162)\n",
            "2\n",
            "✓ Generated tags: {'Topics': ['faith-belief', 'knowledge-scholarship', 'worship-practices', 'character-virtues'], 'Sub-Topics': ['true-believers-characteristics', 'scholars-role', 'prayer-importance', 'charity-significance', 'belief-in-prophets', 'reward-for-righteousness', 'faith-in-allah', 'last-day-accountability']}\n",
            "\n",
            "Processing row 4/13 (ID: 4|163)\n",
            "3\n",
            "✓ Generated tags: {'Topics': ['Prophetic Guidance', 'Divine Revelation', 'Islamic History'], 'Sub-Topics': ['prophetic-messengers', 'divine-inspiration', 'prophet-nuh', 'prophet-ibrahim', 'prophet-isa', 'prophet-dawud', 'revelation-process', 'messenger-role', 'islamic-history', 'prophetic-stories', 'spiritual-guidance', 'divine-wisdom']}\n",
            "\n",
            "Processing row 5/14 (ID: 4|164)\n",
            "4\n",
            "✓ Generated tags: {'Topics': ['prophetic-stories', 'divine-communication', 'messengers-in-islam', 'islamic-beliefs'], 'Sub-Topics': ['prophet-musa', 'messenger-role', 'divine-revelation', 'prophetic-mission', 'allah-attributes', 'islamic-theology']}\n",
            "\n",
            "Processing row 6/15 (ID: 4|165)\n",
            "5\n",
            "✓ Generated tags: {'Topics': ['prophetic-mission', 'divine-revelation', 'accountability', 'divine-attributes'], 'Sub-Topics': ['messengers-role', 'warning-and-guidance', 'divine-justice', 'prophetic-continuity', 'allah-power', 'allah-wisdom']}\n",
            "\n",
            "Processing row 7/16 (ID: 4|166)\n",
            "6\n",
            "✓ Generated tags: {'Topics': ['divine-revelation', 'prophetic-authenticity', 'angelic-testimony', 'islamic-beliefs'], 'Sub-Topics': ['quran-revelation', 'prophetic-verification', 'divine-knowledge', 'angelic-witness', 'allah-shahid', 'prophetic-authentication', 'islamic-theology', 'revelation-authenticity']}\n",
            "\n",
            "Processing row 8/17 (ID: 4|167)\n",
            "7\n",
            "✓ Generated tags: {'Topics': ['disbelief', 'rejection-of-faith', 'obstruction-of-islamic-path', 'divine-guidance', 'spiritual-wandering'], 'Sub-Topics': ['kufr-rejection', 'obstructing-others-from-islam', 'spiritual-misguidance', 'divine-justice', 'path-of-righteousness', 'warning-against-disbelief']}\n",
            "\n",
            "Processing row 9/18 (ID: 4|168)\n",
            "8\n",
            "✓ Generated tags: {'Topics': ['kufr-rejection', 'zulm-injustice', 'divine-forgiveness', 'guidance-hidayah', 'hell-jahannam'], 'Sub-Topics': ['rejection-of-faith', 'wrongdoing-injustice', 'forgiveness-refusal', 'guidance-denial', 'punishment-hellfire', 'divine-justice', 'accountability-hisab']}\n",
            "\n",
            "Processing row 10/19 (ID: 4|169)\n",
            "9\n",
            "✓ Generated tags: {'Topics': ['hell-jahannam', 'divine-justice', 'afterlife-akhirah', 'punishment-reward'], 'Sub-Topics': ['hell-punishment', 'divine-decree', 'eternal-punishment', 'divine-ease']}\n",
            "\n",
            "==================================================\n",
            "PROCESSINGprevious_verse2 COMPLETE!\n",
            "Successfully processed: 10 rows\n",
            "Failed: 0 rows\n",
            "Success rate: 100.0%\n",
            "Total input tokens: 30415\n",
            "Total output tokens: 1025\n",
            "Average tokens per verse: 3041.5 input, 102.5 output\n",
            "Results saved to: /home/nebulamind/Documents/AI Lab/AskDeen/outputs/complete_tags_with_scrapping.csv\n",
            "\n",
            "==================================================\n",
            "VALIDATION RESULTS:\n",
            "Total rows processed: 20\n",
            "Rows with all 3 tags: 0\n",
            "Rows with missing tags: 20\n",
            "Unique tags generated: 0\n",
            "Total tokens used: 31440\n",
            "Average tokens per verse: 1448.3 input, 48.8 output\n",
            "\n",
            "==================================================\n",
            "SAMPLE RESULTS:\n",
            "\n",
            "==================================================\n",
            "PROCESSING COMPLETE!\n",
            "Results saved to: /home/nebulamind/Documents/AI Lab/AskDeen/outputs/complete_tags_with_scrapping.csv\n",
            "Review the generated tags for quality and consistency\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "finetuning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
